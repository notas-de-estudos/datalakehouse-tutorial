# üìò Apache Iceberg

## üìå Introdu√ß√£o
Este tutorial apresenta os conceitos fundamentais do **Data Lakehouse**, com foco no framework **Apache Iceberg**, um formato de tabela moderno que unifica processamento anal√≠tico em data lakes com governan√ßa, consist√™ncia e performance.

O objetivo √© mostrar **como Iceberg funciona**, quais problemas resolve e como utiliz√°-lo em conjunto com servi√ßos da AWS e motores de processamento como Spark.

---

## üßä O que √© o Apache Iceberg?
O **Apache Iceberg** √© um *open table format* projetado para armazenar e gerenciar tabelas anal√≠ticas diretamente sobre armazenamentos como S3, HDFS e GCS.

Ele fornece:

- Transa√ß√µes ACID-like  
- Snapshots versionados  
- Time Travel  
- Schema Evolution sem quebra  
- Suporte multi-engine (Spark, Flink, Trino/Presto, Hive)

Iceberg traz para o data lake funcionalidades semelhantes a bancos anal√≠ticos modernos, mas mantendo custos menores e sem lock-in.

---

## üé¨ Case Real: Netflix
A Netflix adotou Iceberg para escalar suas opera√ß√µes de dados:

- Mais de **10 PB** de dados anal√≠ticos gerenciados por Iceberg  
- Migra√ß√£o de **1,5 milh√£o de tabelas Hive** para Iceberg  
- Necessidade de interoperabilidade:  
  - Cientistas usando **Spark**  
  - Analistas e BI usando **Presto/Trino**

Iceberg se destacou pela performance, governan√ßa e facilidade de manuten√ß√£o.

---

## üèõ Arquitetura do Iceberg

### ‚úî Metadata Layer
Iceberg separa **metadados** dos arquivos f√≠sicos. Isso permite:

- Snapshots versionados  
- Manifestos para indexar arquivos  
- Particionamento evolutivo  
- Evitar full scans desnecess√°rios

### Componentes principais:

| Componente | Fun√ß√£o |
|-----------|--------|
| **Snapshot** | Representa o estado completo da tabela em um momento |
| **Manifest List** | Lista de manifestos pertencentes a um snapshot |
| **Manifest File** | √çndice de arquivos (Parquet/ORC), estat√≠sticas e parti√ß√µes |
| **Data Files** | Arquivos f√≠sicos de dados (Parquet/ORC) |
| **Delete Files** | Arquivos contendo opera√ß√µes de delete |
| **Catalog** | Local onde a tabela √© registrada (Glue, Hive Metastore, Nessie, REST) |

![Arquitetura Apache Iceberg](/2-apache-iceberg/img/arquitetura-iceberg.png)

![Arquitetura Iceberg e Glue](/2-apache-iceberg/img/iceberg-glue.png)

---

## ‚≠ê Vantagens e Recursos-Chave

### üîπ Time Travel & Snapshots
Permite consultar vers√µes antigas da tabela ou fazer rollback.

### üîπ Schema Evolution Seguro
Colunas possuem IDs; mudan√ßas como rename/drop n√£o quebram queries.

### üîπ Hidden Partitioning
O usu√°rio consulta como tabela SQL comum, sem expor estrutura de parti√ß√µes.

### üîπ Isolation e Consist√™ncia
Leitores sempre veem um snapshot consistente, mesmo durante escrituras.

---

## Exemplo de Uso com AWS Glue, S3 e Spark (SQL, e PySpark)

### 1. Criar cat√°logo Iceberg usando o AWS Glue

```python
spark = (
    SparkSession.builder
        .appName("IcebergGlue")
        .config("spark.sql.catalog.glue", "org.apache.iceberg.spark.SparkCatalog")
        .config("spark.sql.catalog.glue.catalog-impl", "org.apache.iceberg.aws.glue.GlueCatalog")
        .config("spark.sql.catalog.glue.warehouse", "s3://meu-bucket/warehouse/")
        .config("spark.sql.catalog.glue.io-impl", "org.apache.iceberg.aws.s3.S3FileIO")
        .getOrCreate()
)
```

### 2. Criar tabela Iceberg no S3

```sql
CREATE TABLE glue.db.pedidos (
  id BIGINT,
  cliente STRING,
  valor DOUBLE,
  ts TIMESTAMP
)
USING iceberg
PARTITIONED BY (days(ts));
```

### 3. Inserir dados via PySpark

```python
df = spark.createDataFrame([
    (1, "Jo√£o", 150.0, "2025-01-01 10:00:00")
], ["id", "cliente", "valor", "ts"])

df.write.format("iceberg").mode("append").save("glue.db.pedidos")
```

### 4. Consultar tabela e snapshots

- Leitura normal

```python
spark.read.format("iceberg").load("glue.db.pedidos").show()
```

- Time Travel por timestamp

```SQL
SELECT * FROM glue.db.pedidos
FOR SYSTEM_TIME AS OF TIMESTAMP '2025-01-01 10:05:00';
```